<HTML>
<HEAD>
 <TITLE>Entropy</TITLE> 
</HEAD>
<BODY>
 <H1>Entropy</H1> 
 <P><H2>Entropy</H2>
</P>
<P><H2>“A measure of the amount of information that is output by a source, or throughput by a channel, or received by an observer (per symbol or second).”</H2>
</P>
<P><H2>Dictionary of Computing, Oxford Scientific publications</H2>
</P>
<P><H2>The entropy of a discrete memoryless source can be regarded as the average amount of information delivered by each symbol.</H2>
</P>
<P><UL><LI>Alphabet A={ai} of size n<LI>output X at time t<LI>p(xi) = Probability{Xi=ai}</UL></P>
<P><H2>Entropy is given:</H2>
</P>
<P></P> 
<P>
<TABLE>
<TD HEIGHT=100 WIDTH=100>

<A HREF = "tsld003.htm">Previous slide </A> </TD>
<TD HEIGHT=100 WIDTH=100>

<A HREF = "tsld005.htm">Next slide </A>  </TD>
<TD HEIGHT=100 WIDTH=150>

<A HREF = "index.htm">Back to the first slide </A>  </TD>
<TD HEIGHT=100 WIDTH=150>

<A HREF = "sld004.htm">View Graphic Version </A>  </TD>
</TABLE>
<BR>
</p>

<FONT size=4><STRONG> Notes: </FONT></STRONG>
<HR SIZE=3>
<P> </P>
<P>e.g.. A could be letters a to z</P>
<P></P>
<P></P>
<P></P>
<P>i.e. i has values 1 to n</P>
<P></P>
<P></P>
<P></P>
<P>p(xi) is the probability of the output symbol ai occurring</P>
<P></P>
<P></P>
<P></P>
<P>entropy is the event probabilities multiplied by the information content provided by  the event, summed for all symbols.</P>
<P> </P> 
</Body>
</HTML>